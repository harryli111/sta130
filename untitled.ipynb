{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03745f06",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952da571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Numerical Summaries**\n",
    "df.describe() # Statistical summaries for numerical columns\n",
    "\n",
    "# **Categorical Summaries** (Example)\n",
    "df['species'].value_counts() # Replace 'species' with the desired column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27269ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample Data (Illustrative)\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "        'Age': [25, 30, None, 28, 35],\n",
    "        'City': ['New York', 'London', 'Tokyo', 'Paris', None]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Dataset Dimensions (df.shape)\n",
    "print(\"DataFrame Shape:\", df.shape)  # Output: (5, 3)\n",
    "\n",
    "# 2. Column Names (df.columns)\n",
    "print(\"\\nDataFrame Columns:\", df.columns)  # Output: Index(['Name', 'Age', 'City'], dtype='object')\n",
    "\n",
    "# 3. Numerical Summaries (df.describe())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "'''\n",
    "# 4. Missing Value Check (df.isna().sum())\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isna().sum()) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50cc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Difference between \"attribute\" and \"method\"\n",
    "Parentheses (): The most apparent visual distinction is the presence or absence of parentheses after the object name (df).\n",
    "Attributes don't have them; methods do.●\n",
    "\n",
    "Action vs. Description: Attributes describe the DataFrame; methods perform actions on the DataFrame, \n",
    "potentially modifying it or returning a new result.●\n",
    "\n",
    "Returning Values: Both attributes and methods can return values. Attributes return the stored value directly. \n",
    "Methods may or may not return a value, depending on their purpose. For example, df.describe() returns a new DataFrame \n",
    "containing the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d771d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "count: This statistic represents the number of non-missing values in a dataset or a specific column (variable) of a dataset. \n",
    "When you use df.describe(), the 'count' value will be lower than the total number of rows if there are missing values in that \n",
    "particular column. This is because df.describe() calculates summaries based on the available, non-missing data points.●\n",
    "mean (Sample Mean): Denoted by $\\bar{x}$, the sample mean is the average of all the non-missing, numerical values in a dataset or a specific \n",
    "    column. It's calculated by summing up all the values and dividing by the number of non-missing values. You can calculate this in Python\n",
    "    using df['column'].mean(), as shown in Source 30.○\n",
    "The mathematical formula for the sample mean is: $$\\displaystyle \\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i$$ where:■\n",
    "$x_i$ represents each individual value in the dataset.■\n",
    "n is the total number of non-missing values.●\n",
    "std (Sample Standard Deviation): Denoted as s, the sample standard deviation measures the spread or dispersion of data points around the mean\n",
    "    . A higher standard deviation indicates that the data points are more spread out from the mean. You can calculate this in Python using df\n",
    "    ['column'].std().○\n",
    "The formula for the sample standard deviation is: $$\\displaystyle s = \\sqrt{s^2} \\text{, where } s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar x\n",
    ")^2$$ where:■\n",
    "$x_i$ represents each individual value.■\n",
    "$\\bar{x}$ is the sample mean.■\n",
    "n is the number of non-missing values.●\n",
    "min (Minimum): This statistic represents the smallest value present in a dataset or a particular column. You can find it using df['column'].\n",
    "    min().●\n",
    "25% (First Quartile - Q1): The first quartile (Q1), also known as the 25th percentile, is the value that separates the lowest 25% of the \n",
    "    data from the rest when the data is arranged in increasing order.●\n",
    "50% (Median - Q2): The median (Q2), or the 50th percentile, represents the middle value of a dataset when it's sorted in ascending order. \n",
    "    It divides the data into two halves. If a dataset has an even number of values, the median is the average of the two middle values.●\n",
    "75% (Third Quartile - Q3): The third quartile (Q3), or 75th percentile, is the value that separates the lowest 75% of the data from the \n",
    "    highest 25% when ordered from least to greatest.●\n",
    "max (Maximum): This is the largest value present in a dataset or a column. You can find it using df['column'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1\n",
    "In a survey dataset with columns for age, income, and opinion on a topic, if a respondent skipped a question (leading to a missing value), \n",
    "and you only want to analyze responses from participants who answered all questions, df.dropna() would be suitable.\n",
    "\n",
    "2 Imagine you have a dataset about houses with columns like square footage, number of bedrooms, and price. If the 'year built' column has a \n",
    "significant amount of missing data, and your analysis focuses on the relationship between price and square footage, you might choose to \n",
    "delete the 'year built' column using del df['year built'].\n",
    "\n",
    "3 You should apply del df['col'] before df.dropna() when you want to first eliminate specific problematic columns with extensive missing data. \n",
    "This can prevent df.dropna() from removing too many rows.\n",
    "\n",
    "4 Hypothetical Dataset●\n",
    "Justification: Since the provided sources do not include a specific dataset to work with, a hypothetical dataset and analysis will be used \n",
    "to illustrate this concept.\n",
    "In this example, we might choose to:1.\n",
    "del df['Salary']: Remove the 'Salary' column because we decide it's not relevant to our current analysis, and it has a missing value.2.\n",
    "df.dropna(subset=['Age']): Remove any rows with missing values in the 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeafbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code performs a grouped summary analysis on your DataFrame (df). Here's a step-by-step explanation:1.\n",
    "df.groupby(\"col1\"): This part of the code groups the DataFrame df based on the unique values in the column named \"col1\". Essentially, \n",
    "    it creates subsets of your data for each distinct value in \"col1\".2.\n",
    "[\"col2\"]: This selects the specific column \"col2\" from each of the groups created in the previous step. We're now focusing on analyzing \n",
    "    the values within \"col2\" for each group in \"col1\".3.\n",
    ".describe(): This applies the .describe() method to each group's \"col2\" data. As we've discussed earlier and as explained in the sources, .\n",
    "    describe() provides descriptive statistics (count, mean, standard deviation, min, 25th percentile, median, 75th percentile, max) for \n",
    "    numerical columns in a DataFrame.\n",
    "    \n",
    "import pandas as pd \n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url) \n",
    "titanic_df.groupby(\"pclass\")[\"age\"].describe()\n",
    "\n",
    "df.describe(): 'Count' is driven by missing values within each individual column across the entire dataset.●\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): 'Count' is determined by non-missing values in 'col2' within each group formed by 'col1'.\n",
    "Missing data in other columns might indirectly affect the 'count' in the grouped analysis if those missing values lead to entire rows being \n",
    "excluded from a particular group. However, the primary driver is the presence of non-missing values in 'col2' within each group.\n",
    "\n",
    "A  .\n",
    "Add the Import Statement: In a code cell at the beginning of your notebook (or before you try to use any Pandas functions), include the line:2.\n",
    "Run the Cell: Execute the code cell containing the import statement. This will load the Pandas library into your session.\n",
    "    \n",
    "B 1.\n",
    "Typo in the File Name: Double-check that you've typed the file name correctly. As your query suggests, even a small typo (like \"titanics.csv\"\n",
    "    instead of \"titanic.csv\") will cause this error.2.\n",
    "File Not in the Current Directory: If the file is located in a different folder than your notebook, Python won't find it. You can \n",
    "    either:○\n",
    "Provide the Full Path: Specify the complete path to the file in your pd.read_csv() function. For example:○\n",
    "Move the File: Move \"titanic.csv\" to the same directory as your Jupyter Notebook file.\n",
    "    ●\n",
    "Incorrect File Type: If you mistype the file extension (e.g., \"titanic.txt\" instead of \"titanic.csv\"), you might successfully download a file,\n",
    "    but it won't be the correct type for your analysis. You'll likely encounter  errors when trying to read the data using pd.read_csv().\n",
    "    ●404 Not Found: Typos within the URL itself (e.g., a misspelled domain name or incorrect path) will often result in a \"404 Not Found\" \n",
    "        error, indicating the web server couldn't find the requested resource (the dataset file).\n",
    "        \n",
    "C df.groupby(\"pclass\")[\"age\"].describe()\n",
    "\n",
    "D pd.read_csv(url) \n",
    "\n",
    "E 1.\n",
    "df.groupby(\"col1\"): Groups the DataFrame df by the values in the \"col1\" column.2.\n",
    "[\"col2\"]: Selects the \"col2\" column from the result of the grouping. You'll now have a Series or DataFrameGroupBy object.3.\n",
    ".describe(): Calculates descriptive statistics on the selected column (from the grouped data).\n",
    "\n",
    "F Case Sensitivity: Column names in Pandas are case-sensitive. \"sex\" and \"Sex\" are treated as completely different columns.●\n",
    "Typos Matter: Double-check your column names for any spelling errors.●\n",
    "Use Existing Column Names: Before running your code, make sure the column names you're using actually exist in your DataFrame. \n",
    "    You can print titanic_df.columns to see a list of valid column names.\n",
    "     \n",
    "G Strings vs. Variables: In Python, you enclose strings in single or double quotes (e.g., \"sex\", 'age'). This distinguishes them from \n",
    "    variable names, which are not enclosed in quotes.●\n",
    "Pandas Syntax: Pandas uses strings within its functions (like groupby and when selecting columns using brackets []) to identify the columns\n",
    "    you want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "9 yes"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
